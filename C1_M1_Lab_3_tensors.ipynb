{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shmokhsidi79-design/week4labs/blob/main/C1_M1_Lab_3_tensors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Icus26frDEgQ"
      },
      "source": [
        "# Tensors: The Core of PyTorch\n",
        "\n",
        "You've seen that the journey of building a neural network begins with data. Before you can design a model or start the training process, you must gather your information and prepare it in a format the model can understand. In PyTorch, that fundamental format is the **tensor**. Tensors are more than just data containers; they are optimized for the mathematical operations that power deep learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBz_vSkxDEgZ"
      },
      "source": [
        "\n",
        "## Why Tensors Matter\n",
        "\n",
        "In the last lab, you trained a model to predict delivery times. And along the way, you've been using tensors, maybe without thinking too much about them. And that's fine until it isn't. **Many PyTorch errors come from tensor issues.** So let's build up your tensor skills now before those errors might derail your projects.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-EnuZlyDEga"
      },
      "source": [
        "\n",
        "## Common Tensor Errors\n",
        "\n",
        "Mastering tensors is a vital step. Many of the most common errors encountered when building models are related to:\n",
        "\n",
        "* **Tensor shapes**: Shape mismatches are one of the most common PyTorch errors. When you hit a shape mismatch, PyTorch will tell you what's wrong, but not how to fix it. Once you see both shapes, usually the fix will be obvious.\n",
        "\n",
        "* **Data types (dtype)**: Providing data of the wrong type, such as an integer when your model expects floats, can lead to runtime errors or unexpected behavior during training.\n",
        "\n",
        "* **Dimensions**: One of the most common shape errors is forgetting the batch dimension. Models expect input with a batch dimension, like `[6, 1]` where the first number tells the model how many samples it's getting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyF17a3vDEgb"
      },
      "source": [
        "\n",
        "## What You'll Learn\n",
        "\n",
        "In this lab, you will learn how to:\n",
        "\n",
        "* **Create tensors** from different data sources like Python lists, NumPy arrays, and pandas DataFrames.\n",
        "\n",
        "* **Check tensor shapes** - the most important tool in your tensor toolkit. Understanding shapes tells you exactly how your data is organized.\n",
        "\n",
        "* **Handle data types** - ensuring your tensors have the correct type (typically float32 for neural networks).\n",
        "\n",
        "* **Reshape and manipulate tensor dimensions** to prepare data for model inputs, including adding and removing batch dimensions.\n",
        "\n",
        "* **Use indexing and slicing techniques** to access and filter specific parts of your data.\n",
        "\n",
        "* **Perform mathematical and logical operations** that form the basis of all neural network computations, including element-wise operations and broadcasting.\n",
        "\n",
        "By the end of this notebook, you will have the practical skills needed to confidently manage the data for any PyTorch project and debug the most common tensor-related errors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVPfqf3fDEgb"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": [],
        "id": "XuoA0wezDEgc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc1u5-xqDEgd"
      },
      "source": [
        "## 1 - Tensor Creation\n",
        "\n",
        "The first step in any machine learning pipeline is getting your data ready for the model. In PyTorch, this means loading your data into tensors. You will find that there are several convenient ways to create tensors, whether your data is already in another format or you need to generate it from scratch.\n",
        "\n",
        "### 1.1 From Existing Data Structures\n",
        "\n",
        "Often, your raw data will be in a common format like a Python list, a NumPy array, or a pandas DataFrame. PyTorch provides straightforward functions to convert these structures into tensors, making the data preparation stage more efficient.\n",
        "\n",
        "* `torch.tensor()`: This function takes input such as a Python list to convert it into a tensor.\n",
        "\n",
        "**Note:** The type of numbers you use matters. If you use integers, PyTorch stores them as integers. If you include decimals, they'll be stored as floating point values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUJZM4lJDEge",
        "outputId": "fa4ea9cc-c508-445a-a8a4-e52aa5073ba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FROM PYTHON LISTS: tensor([1, 2, 3])\n",
            "TENSOR DATA TYPE: torch.int64\n"
          ]
        }
      ],
      "source": [
        "# From Python lists\n",
        "x = torch.tensor([1, 2, 3])\n",
        "\n",
        "print(\"FROM PYTHON LISTS:\", x)\n",
        "print(\"TENSOR DATA TYPE:\", x.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5GmJRmZDEgf"
      },
      "source": [
        "<br>\n",
        "\n",
        "* `torch.from_numpy()`: Converts a NumPy array into a PyTorch tensor.\n",
        "    * If you're coming from NumPy, PyTorch tensors behave almost exactly the same way.\n",
        "    * **Important**: This shares memory. If you change one, then the other changes too. Be careful when modifying tensors created this way!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "700M8lODDEgg",
        "outputId": "588c9e24-2b72-480a-ee40-fd4776ad9d96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TENSOR FROM NUMPY:\n",
            "\n",
            " tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ],
      "source": [
        "# From a NumPy array\n",
        "numpy_array = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "torch_tensor_from_numpy = torch.from_numpy(numpy_array)\n",
        "\n",
        "print(\"TENSOR FROM NUMPY:\\n\\n\", torch_tensor_from_numpy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BAu4PgzDEgh"
      },
      "source": [
        "<br>\n",
        "\n",
        "* **From a pandas DataFrame**: Pandas is a Python library for working with data organized in rows and columns, like a CSV file or spreadsheet. A DataFrame is pandas' main data structure for storing this kind of tabular data. DataFrames are one of the most common ways to load and explore datasets in machine learning, especially when reading CSV files. There isn't a direct function to convert a DataFrame to a tensor. The standard method is to extract the data from the DataFrame into a NumPy array using the `.values` attribute, and then convert that array into a tensor using `torch.tensor()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIg9hnY_DEgh",
        "outputId": "43ecc856-1413-4641-a2a4-cd0ba51ace77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL DATAFRAME:\n",
            "\n",
            "    distance_miles  delivery_time_minutes\n",
            "0            1.60                   7.22\n",
            "1           13.09                  32.41\n",
            "2            6.97                  17.47\n",
            "\n",
            "RESULTING TENSOR:\n",
            "\n",
            " tensor([[ 1.6000,  7.2200],\n",
            "        [13.0900, 32.4100],\n",
            "        [ 6.9700, 17.4700]], dtype=torch.float64)\n",
            "\n",
            "TENSOR DATA TYPE: torch.float64\n"
          ]
        }
      ],
      "source": [
        "# From Pandas DataFrame\n",
        "# Read the data from the CSV file into a DataFrame\n",
        "df = pd.read_csv('./data.csv')\n",
        "\n",
        "# Extract the data as a NumPy array from the DataFrame\n",
        "all_values = df.values\n",
        "\n",
        "# Convert the DataFrame's values to a PyTorch tensor\n",
        "tensor_from_df = torch.tensor(all_values)\n",
        "\n",
        "print(\"ORIGINAL DATAFRAME:\\n\\n\", df)\n",
        "print(\"\\nRESULTING TENSOR:\\n\\n\", tensor_from_df)\n",
        "print(\"\\nTENSOR DATA TYPE:\", tensor_from_df.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NU7pyES4DEgh"
      },
      "source": [
        "### 1.2 - With Predefined Values\n",
        "\n",
        "Sometimes you need to create tensors for specific purposes, like initializing a model's weights and biases before training begins. PyTorch allows you to quickly generate tensors filled with placeholder values like zeros, ones, or random numbers, which is useful for testing and setup.\n",
        "\n",
        "* `torch.zeros()`: Creates a tensor filled with zeros of the specified dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8U1MKvfDEgi",
        "outputId": "09badecf-aadc-44af-9385-fccfcf47b05a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TENSOR WITH ZEROS:\n",
            "\n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "# All zeros\n",
        "zeros = torch.zeros(2, 3)\n",
        "\n",
        "print(\"TENSOR WITH ZEROS:\\n\\n\", zeros)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7bbXD4BDEgi"
      },
      "source": [
        "<br>\n",
        "\n",
        "* `torch.ones()`: Creates a tensor filled with ones of the specified dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkLbicUTDEgi",
        "outputId": "b92f89ac-b772-4408-be9e-cdabfb6f8480"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TENSOR WITH ONES:\n",
            "\n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "# All ones\n",
        "ones = torch.ones(2, 3)\n",
        "\n",
        "print(\"TENSOR WITH ONES:\\n\\n\", ones)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8N5EczYDEgi"
      },
      "source": [
        "<br>\n",
        "\n",
        "* `torch.rand()`: Generates a tensor with random numbers uniformly distributed between 0 and 1, based on the specified dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSTgintPHYdf",
        "outputId": "34a1ed42-498f-43ca-b058-cbe22407c775",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RANDOM TENSOR:\n",
            "\n",
            " tensor([[0.4622, 0.6178, 0.3228],\n",
            "        [0.1027, 0.9785, 0.7508]])\n"
          ]
        }
      ],
      "source": [
        "# Random numbers\n",
        "random = torch.rand(2, 3)\n",
        "\n",
        "print(\"RANDOM TENSOR:\\n\\n\", random)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12vlzg4EDEgj"
      },
      "source": [
        "### 1.3 - From a Sequence\n",
        "\n",
        "For situations where you need to generate a sequence of data points, such as a range of values for testing a model's predictions, you can create a tensor directly from that sequence.\n",
        "\n",
        "* `torch.arange()`: Creates a 1D tensor containing a range of numbers from the specified start value to one less than the specified stop value, incrementing (if positive) or decrementing (if negative) by the specified `step` value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1xzmXttDEgj",
        "outputId": "58040ee6-3247-4ef0-bd14-df26333ed13e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ARANGE TENSOR: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
          ]
        }
      ],
      "source": [
        "# Range of numbers\n",
        "range_tensor = torch.arange(0, 10, step=1)\n",
        "\n",
        "print(\"ARANGE TENSOR:\", range_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M90uKQYkDEgj"
      },
      "source": [
        "## 2 - Reshaping & Manipulating\n",
        "\n",
        "A very common source of errors in PyTorch projects is a mismatch between the shape of your input data and the shape your model expects. For instance, a model is typically designed to process a batch of data, so even if you want to make a single prediction, you must shape your input tensor to look like a batch of one. Mastering tensor reshaping is a key step toward building and debugging models effectively.\n",
        "\n",
        "### 2.1 - Checking a Tensor's Dimensions\n",
        "\n",
        "The first step to fixing a shape mismatch is to understand the current dimensions of your tensor. **Checking the shape is your primary debugging tool.** It tells you how many samples you have and how many features are in each sample.\n",
        "\n",
        "**Understanding Tensor Shapes**\n",
        "\n",
        "When you print `tensor.shape`, you'll get something like `torch.Size([6, 1])`. This tells you exactly how your data is organized:\n",
        "- The first dimension (`6`) is the **batch size** - how many samples you have\n",
        "- The second dimension (`1`) is the **number of features** per sample\n",
        "\n",
        "Think of it a little bit like a stack of papers. The model reads each page the same way, whether there are six pages or 600 in the stack. **The first dimension is how many, and the rest describe what each sample looks like.**\n",
        "\n",
        "For example, with a shape of `[6, 1]`:\n",
        "- There are 6 samples (deliveries)\n",
        "- Each sample has 1 feature (distance)\n",
        "\n",
        "If you had multiple features like distance, hour, and weather, the shape might be `[6, 3]`:\n",
        "- There are 6 samples\n",
        "- Each sample has 3 features\n",
        "\n",
        "**Why Shape Matters**\n",
        "\n",
        "Shape mismatches are one of the most common PyTorch errors. When you hit a shape mismatch, PyTorch will tell you what's wrong, but not how to fix it. Once you see both shapes, usually the fix will be obvious.\n",
        "\n",
        "For example, if your model expects `[batch_size, 1]` (one feature per sample) but you pass in `[batch_size, 3]` (three features), it will fail. The model was only built for one input feature.\n",
        "\n",
        "* `torch.Tensor.shape`: An attribute that returns a `torch.Size` object detailing the size of the tensor along each dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEc2CicSDEgk",
        "outputId": "a8e9efcc-2e9f-4f59-aa46-879d17395dd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL TENSOR:\n",
            "\n",
            " tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "\n",
            "TENSOR SHAPE: torch.Size([2, 3])\n"
          ]
        }
      ],
      "source": [
        "# A 2D tensor\n",
        "x = torch.tensor([[1, 2, 3],\n",
        "                  [4, 5, 6]])\n",
        "\n",
        "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
        "print(\"\\nTENSOR SHAPE:\", x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZ-9fEjvDEgk"
      },
      "source": [
        "### 2.2 - Changing a Tensor's Dimensions\n",
        "\n",
        "Once you identify a shape mismatch, you need to correct it. A frequent task is adding a dimension to a single data sample to create a batch of size one for your model, or removing a dimension after a batch operation is complete.\n",
        "\n",
        "**The Most Common Shape Error: Forgetting the Batch Dimension**\n",
        "\n",
        "One of the most common shape errors is forgetting the batch dimension. Remember, PyTorch models expect input with a batch dimension, like `[6, 1]` that we saw earlier. That first number tells the model how many samples it's getting.\n",
        "\n",
        "Let's say you want to predict the delivery time for a single order, for example, 25 miles. This is a scalar, but your model expects a shape of `[batch_size, features]`, which at a minimum is `[1, 1]`. You need to add that batch dimension!\n",
        "\n",
        "**Always check the shape before you use `unsqueeze()`.** And if you're going the other way, try just using `squeeze()`. `squeeze()` removes all dimensions of size one, and it's great for cleaning up after batching.\n",
        "\n",
        "**Always print `tensor.shape` when you're debugging.** These tools are your first defense against shape errors.\n",
        "\n",
        "* **Adding Dimension:** `torch.Tensor.unsqueeze()` inserts a new dimension at the specified index.\n",
        "    * *Notice how the shape will change from `[2, 3]` to `[1, 2, 3]` and the tensor gets wrapped in an extra pair of square brackets `[]`*.\n",
        "    * Use this when you have a single sample and need to add a batch dimension for your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVDwWRT6DEgk",
        "outputId": "7380b06c-5e2f-4136-ab07-01505c06ef27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL TENSOR:\n",
            "\n",
            " tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "\n",
            "TENSOR SHAPE: torch.Size([2, 3])\n",
            "---------------------------------------------\n",
            "\n",
            "TENSOR WITH ADDED DIMENSION AT INDEX 0:\n",
            "\n",
            " tensor([[[1, 2, 3],\n",
            "         [4, 5, 6]]])\n",
            "\n",
            "TENSOR SHAPE: torch.Size([1, 2, 3])\n"
          ]
        }
      ],
      "source": [
        "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
        "print(\"\\nTENSOR SHAPE:\", x.shape)\n",
        "print(\"-\"*45)\n",
        "\n",
        "# Add dimension\n",
        "expanded = x.unsqueeze(0)  # Add dimension at index 0\n",
        "\n",
        "print(\"\\nTENSOR WITH ADDED DIMENSION AT INDEX 0:\\n\\n\", expanded)\n",
        "print(\"\\nTENSOR SHAPE:\", expanded.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF7mpHU-DEgl"
      },
      "source": [
        "<br>\n",
        "\n",
        "* **Removing Dimension:** `torch.Tensor.squeeze()` removes dimensions of size 1.\n",
        "    * *This reverses the unsqueeze operation, removing the `1` from the shape and taking away a pair of outer square brackets*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCp_jvJ1DEgl",
        "outputId": "f710ecd1-f799-443f-c4f3-51d4bc1c73b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXPANDED TENSOR:\n",
            "\n",
            " tensor([[[1, 2, 3],\n",
            "         [4, 5, 6]]])\n",
            "\n",
            "TENSOR SHAPE: torch.Size([1, 2, 3])\n",
            "---------------------------------------------\n",
            "\n",
            "TENSOR WITH DIMENSION REMOVED:\n",
            "\n",
            " tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "\n",
            "TENSOR SHAPE: torch.Size([2, 3])\n"
          ]
        }
      ],
      "source": [
        "print(\"EXPANDED TENSOR:\\n\\n\", expanded)\n",
        "print(\"\\nTENSOR SHAPE:\", expanded.shape)\n",
        "print(\"-\"*45)\n",
        "\n",
        "# Remove dimension\n",
        "squeezed = expanded.squeeze()\n",
        "\n",
        "print(\"\\nTENSOR WITH DIMENSION REMOVED:\\n\\n\", squeezed)\n",
        "print(\"\\nTENSOR SHAPE:\", squeezed.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjD1xBVODEgl"
      },
      "source": [
        "### 2.3 - Restructuring\n",
        "\n",
        "Beyond just adding or removing dimensions, you may need to completely change a tensor's structure to match the requirements of a specific layer or operation within your neural network.\n",
        "\n",
        "* **Reshaping:** `torch.Tensor.reshape()` changes the shape of a tensor to the specified dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBUel324DEgm",
        "outputId": "5977025d-cee8-463a-f7c9-a09c7c21af21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL TENSOR:\n",
            "\n",
            " tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "\n",
            "TENSOR SHAPE: torch.Size([2, 3])\n",
            "---------------------------------------------\n",
            "\n",
            "AFTER PERFORMING reshape(3, 2):\n",
            "\n",
            " tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "\n",
            "TENSOR SHAPE: torch.Size([3, 2])\n"
          ]
        }
      ],
      "source": [
        "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
        "print(\"\\nTENSOR SHAPE:\", x.shape)\n",
        "print(\"-\"*45)\n",
        "\n",
        "# Reshape\n",
        "reshaped = x.reshape(3, 2)\n",
        "\n",
        "print(\"\\nAFTER PERFORMING reshape(3, 2):\\n\\n\", reshaped)\n",
        "print(\"\\nTENSOR SHAPE:\", reshaped.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muZZtkyoDEgn"
      },
      "source": [
        "* **Transposing:** `torch.Tensor.transpose()` swaps the specified dimensions of a tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9Bjx0rXDEgn",
        "outputId": "661d9eea-355f-4449-f205-1bb1b7bf88a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL TENSOR:\n",
            "\n",
            " tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "\n",
            "TENSOR SHAPE: torch.Size([2, 3])\n",
            "---------------------------------------------\n",
            "\n",
            "AFTER PERFORMING transpose(0, 1):\n",
            "\n",
            " tensor([[1, 4],\n",
            "        [2, 5],\n",
            "        [3, 6]])\n",
            "\n",
            "TENSOR SHAPE: torch.Size([3, 2])\n"
          ]
        }
      ],
      "source": [
        "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
        "print(\"\\nTENSOR SHAPE:\", x.shape)\n",
        "print(\"-\"*45)\n",
        "\n",
        "# Transpose\n",
        "transposed = x.transpose(0, 1)\n",
        "\n",
        "print(\"\\nAFTER PERFORMING transpose(0, 1):\\n\\n\", transposed)\n",
        "print(\"\\nTENSOR SHAPE:\", transposed.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "tags": [],
        "id": "7WajiXcYDEgo"
      },
      "outputs": [],
      "source": [
        "assert x.transpose(0, 1).shape == x.transpose(1, 0).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-iLaAflDEgo"
      },
      "source": [
        "### 2.4 - Combining Tensors\n",
        "\n",
        "In the data preparation stage, you might need to combine data from different sources or merge separate batches into one larger dataset.\n",
        "\n",
        "* `torch.cat()`: Joins a sequence of tensors along an existing dimension. Note: All tensors must have the same shape in dimensions other than the one being concatenated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsTi6s8TDEgo",
        "outputId": "e76d4123-731a-4a84-a821-acfd7e3f3473"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TENSOR A:\n",
            "\n",
            " tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "\n",
            "TENSOR B:\n",
            "\n",
            " tensor([[5, 6],\n",
            "        [7, 8]])\n",
            "---------------------------------------------\n",
            "\n",
            "CONCATENATED TENSOR (dim=1):\n",
            "\n",
            " tensor([[1, 2, 5, 6],\n",
            "        [3, 4, 7, 8]])\n"
          ]
        }
      ],
      "source": [
        "# Create two tensors to concatenate\n",
        "tensor_a = torch.tensor([[1, 2],\n",
        "                         [3, 4]])\n",
        "tensor_b = torch.tensor([[5, 6],\n",
        "                         [7, 8]])\n",
        "\n",
        "# Concatenate along columns (dim=1)\n",
        "concatenated_tensors = torch.cat((tensor_a, tensor_b), dim=1)\n",
        "\n",
        "\n",
        "print(\"TENSOR A:\\n\\n\", tensor_a)\n",
        "print(\"\\nTENSOR B:\\n\\n\", tensor_b)\n",
        "print(\"-\"*45)\n",
        "print(\"\\nCONCATENATED TENSOR (dim=1):\\n\\n\", concatenated_tensors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnQmWAd3DEgo"
      },
      "source": [
        "## 3 - Indexing & Slicing\n",
        "\n",
        "After you have your data in a tensor, you will often need to access specific parts of it. Whether you are grabbing a single prediction to inspect its value, separating your input features from your labels, or selecting a subset of data for analysis, indexing and slicing are the tools for the job.\n",
        "\n",
        "### 3.1 - Accessing Elements\n",
        "\n",
        "These are the fundamental techniques for getting data out of a tensor, working very similarly to how you would access elements in a standard Python list.\n",
        "\n",
        "* **Standard Indexing**: Accessing single elements or entire rows using integer indices (e.g., `x[0]`, `x[1, 2]`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V21-YNgcDEgo",
        "outputId": "cca12a61-c0bf-4aef-812f-9a00cd15001c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL TENSOR:\n",
            "\n",
            " tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]])\n",
            "-------------------------------------------------------\n",
            "\n",
            "INDEXING SINGLE ELEMENT AT [1, 2]: tensor(7)\n",
            "-------------------------------------------------------\n",
            "\n",
            "INDEXING ENTIRE ROW [1]: tensor([5, 6, 7, 8])\n",
            "-------------------------------------------------------\n",
            "\n",
            "INDEXING ENTIRE LAST ROW ([-1]): tensor([ 9, 10, 11, 12]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a 3x4 tensor\n",
        "x = torch.tensor([\n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8],\n",
        "    [9, 10, 11, 12]\n",
        "])\n",
        "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
        "print(\"-\" * 55)\n",
        "\n",
        "# Get a single element at row 1, column 2\n",
        "single_element_tensor = x[1, 2]\n",
        "\n",
        "print(\"\\nINDEXING SINGLE ELEMENT AT [1, 2]:\", single_element_tensor)\n",
        "print(\"-\" * 55)\n",
        "\n",
        "# Get the entire second row (index 1)\n",
        "second_row = x[1]\n",
        "\n",
        "print(\"\\nINDEXING ENTIRE ROW [1]:\", second_row)\n",
        "print(\"-\" * 55)\n",
        "\n",
        "# Last row\n",
        "last_row = x[-1]\n",
        "\n",
        "print(\"\\nINDEXING ENTIRE LAST ROW ([-1]):\", last_row, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdr5XYHEDEgp"
      },
      "source": [
        "<br>\n",
        "\n",
        "* **Slicing**: Extracting sub-tensors using `[start:end:step]` notation (e.g., `x[:2, ::2]`).\n",
        "    * *Note: The `end` index itself is not included in the slice.*\n",
        "* Slicing can be used to access entire columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rq5KUU2CDEgp",
        "outputId": "383e0e68-1d75-43f9-8bd3-f07cc4445539"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL TENSOR:\n",
            "\n",
            " tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]])\n",
            "-------------------------------------------------------\n",
            "\n",
            "SLICING FIRST TWO ROWS ([0:2]):\n",
            "\n",
            " tensor([[1, 2, 3, 4],\n",
            "        [5, 6, 7, 8]])\n",
            "-------------------------------------------------------\n",
            "\n",
            "SLICING THIRD COLUMN ([:, 2]]): tensor([ 3,  7, 11])\n",
            "-------------------------------------------------------\n",
            "\n",
            "EVERY OTHER COLUMN ([:, ::2]):\n",
            "\n",
            " tensor([[ 1,  3],\n",
            "        [ 5,  7],\n",
            "        [ 9, 11]])\n",
            "-------------------------------------------------------\n",
            "\n",
            "LAST COLUMN ([:, -1]): tensor([ 4,  8, 12]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
        "print(\"-\" * 55)\n",
        "\n",
        "# Get the first two rows\n",
        "first_two_rows = x[0:2]\n",
        "\n",
        "print(\"\\nSLICING FIRST TWO ROWS ([0:2]):\\n\\n\", first_two_rows)\n",
        "print(\"-\" * 55)\n",
        "\n",
        "# Get the third column of all rows\n",
        "third_column = x[:, 2]\n",
        "\n",
        "print(\"\\nSLICING THIRD COLUMN ([:, 2]]):\", third_column)\n",
        "print(\"-\" * 55)\n",
        "\n",
        "# Every other column\n",
        "every_other_col = x[:, ::2]\n",
        "\n",
        "print(\"\\nEVERY OTHER COLUMN ([:, ::2]):\\n\\n\", every_other_col)\n",
        "print(\"-\" * 55)\n",
        "\n",
        "# Last column\n",
        "last_col = x[:, -1]\n",
        "\n",
        "print(\"\\nLAST COLUMN ([:, -1]):\", last_col, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tuz2mqCGDEgp"
      },
      "source": [
        "* Combining Indexing & Slicing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXw8VUTBDEgq",
        "outputId": "6243c29a-3f85-4768-fa57-2a9bf889a72e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL TENSOR:\n",
            "\n",
            " tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]])\n",
            "-------------------------------------------------------\n",
            "\n",
            "FIRST TWO ROWS, LAST TWO COLS ([0:2, 2:]):\n",
            "\n",
            " tensor([[3, 4],\n",
            "        [7, 8]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
        "print(\"-\" * 55)\n",
        "\n",
        "# Combining slicing and indexing (First two rows, last two columns)\n",
        "combined = x[0:2, 2:]\n",
        "\n",
        "print(\"\\nFIRST TWO ROWS, LAST TWO COLS ([0:2, 2:]):\\n\\n\", combined, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTCyXm82DEgz"
      },
      "source": [
        "<br>\n",
        "\n",
        "* **`.item()`**: Extracts the value from a single-element tensor as a standard Python number.\n",
        "    * Even a single index value is still a tensor. So if you want the actual Python value (like a float or int), use `.item()` to convert it into a Python number.\n",
        "    * **Be careful**: `.item()` only works on tensors with exactly one element. Call it on a bigger tensor, and you'll get an error.\n",
        "    * This is especially useful when you want to check predictions or use tensor values in Python conditionals or print statements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jel-DhBIDEg0",
        "outputId": "16525522-e2f9-4f1d-9a2e-495cc71a304e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SINGLE-ELEMENT TENSOR: tensor(7)\n",
            "---------------------------------------------\n",
            "\n",
            ".item() PYTHON NUMBER EXTRACTED: 7\n",
            "TYPE: <class 'int'>\n"
          ]
        }
      ],
      "source": [
        "print(\"SINGLE-ELEMENT TENSOR:\", single_element_tensor)\n",
        "print(\"-\" * 45)\n",
        "\n",
        "# Extract the value from a single-element tensor as a standard Python number\n",
        "value = single_element_tensor.item()\n",
        "\n",
        "print(\"\\n.item() PYTHON NUMBER EXTRACTED:\", value)\n",
        "print(\"TYPE:\", type(value))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoJBkcjADEg1"
      },
      "source": [
        "### 3.2 - Advanced Indexing\n",
        "\n",
        "For more complex data selection, such as filtering your dataset based on one or more conditions, you can use advanced indexing techniques.\n",
        "\n",
        "* **Boolean Masking**: Using a boolean tensor to select elements that meet a certain condition (e.g., `x[x > 5]`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxH1gfmwDEg1",
        "outputId": "064e6d54-33db-416d-82d6-30a925338aef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL TENSOR:\n",
            "\n",
            " tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]])\n",
            "-------------------------------------------------------\n",
            "MASK (VALUES > 6):\n",
            "\n",
            " tensor([[False, False, False, False],\n",
            "        [False, False,  True,  True],\n",
            "        [ True,  True,  True,  True]]) \n",
            "\n",
            "VALUES AFTER APPLYING MASK: tensor([ 7,  8,  9, 10, 11, 12]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
        "print(\"-\" * 55)\n",
        "\n",
        "# Boolean indexing using logical comparisons\n",
        "mask = x > 6\n",
        "\n",
        "print(\"MASK (VALUES > 6):\\n\\n\", mask, \"\\n\")\n",
        "\n",
        "# Applying Boolean masking\n",
        "mask_applied = x[mask]\n",
        "\n",
        "print(\"VALUES AFTER APPLYING MASK:\", mask_applied, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6XI4jBoDEg2"
      },
      "source": [
        "<br>\n",
        "\n",
        "* **Fancy Indexing**: Using a tensor of indices to select specific elements in a non-contiguous way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJUaRp0WDEg2",
        "outputId": "517068b8-74ee-4592-9b58-d38affbac7a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL TENSOR:\n",
            "\n",
            " tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]])\n",
            "-------------------------------------------------------\n",
            "\n",
            "SPECIFIC ELEMENTS USING INDICES:\n",
            "\n",
            " tensor([[ 2,  4],\n",
            "        [10, 12]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
        "print(\"-\" * 55)\n",
        "\n",
        "# Fancy indexing\n",
        "\n",
        "# Get first and third rows\n",
        "row_indices = torch.tensor([0, 2])\n",
        "\n",
        "# Get second and fourth columns\n",
        "col_indices = torch.tensor([1, 3])\n",
        "\n",
        "# Gets values at (0,1), (0,3), (2,1), (2,3)\n",
        "get_values = x[row_indices[:, None], col_indices]\n",
        "\n",
        "print(\"\\nSPECIFIC ELEMENTS USING INDICES:\\n\\n\", get_values, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CecWzL7kDEg2"
      },
      "source": [
        "## 4 - Mathematical & Logical Operations\n",
        "\n",
        "At their core, neural networks are performing mathematical computations. A single neuron, for example, calculates a weighted sum of its inputs and adds a bias. PyTorch is optimized to perform these operations efficiently across entire tensors at once, which is what makes training so fast.\n",
        "\n",
        "**How PyTorch Computes with Tensors**\n",
        "\n",
        "Let's start with a computation from your single neuron model: `weight × distance + bias`. Here's what that looks like when you have multiple distances to process. PyTorch's tensor math works **element-wise**, so each element is operated on independently. Your computation applies the same weight to each distance, and then adds the same bias to each result. The math looks just like regular Python, but PyTorch runs these operations efficiently on all elements at once.\n",
        "\n",
        "This works for scalars (single values) as well as tensors that have the same shape. But what if you have more complex data? That's where **broadcasting** comes in.\n",
        "\n",
        "### 4.1 - Arithmetic\n",
        "\n",
        "These operations are the foundation of how a neural network processes data. You'll see how PyTorch handles element-wise calculations and uses a powerful feature called broadcasting to simplify your code.\n",
        "\n",
        "* **Element-wise Operations**: Standard math operators (`+`, `*`) that apply to each element independently.\n",
        "    * When tensors have the same shape, operations work element by element.\n",
        "    * Each element in the first tensor is paired with the corresponding element in the second tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PJbCRygDEg3",
        "outputId": "c030dfb2-d94d-4dd7-9a99-e0d03ac27b8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TENSOR A: tensor([1, 2, 3])\n",
            "TENSOR B tensor([4, 5, 6])\n",
            "------------------------------------------------------------\n",
            "\n",
            "AFTER PERFORMING ELEMENT-WISE ADDITION: tensor([5, 7, 9]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([1, 2, 3])\n",
        "b = torch.tensor([4, 5, 6])\n",
        "print(\"TENSOR A:\", a)\n",
        "print(\"TENSOR B\", b)\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Element-wise addition\n",
        "element_add = a + b\n",
        "\n",
        "print(\"\\nAFTER PERFORMING ELEMENT-WISE ADDITION:\", element_add, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bl5EBxbuDEg3",
        "outputId": "0d7c09cb-556c-40d6-f4fd-559c2bcb3514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TENSOR A: tensor([1, 2, 3])\n",
            "TENSOR B tensor([4, 5, 6])\n",
            "-----------------------------------------------------------------\n",
            "\n",
            "AFTER PERFORMING ELEMENT-WISE MULTIPLICATION: tensor([ 4, 10, 18]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"TENSOR A:\", a)\n",
        "print(\"TENSOR B\", b)\n",
        "print(\"-\" * 65)\n",
        "\n",
        "# Element-wise multiplication\n",
        "element_mul = a * b\n",
        "\n",
        "print(\"\\nAFTER PERFORMING ELEMENT-WISE MULTIPLICATION:\", element_mul, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uWftPpaDEg3"
      },
      "source": [
        "<br>\n",
        "\n",
        "* **Dot Product (`torch.matmul()`)**: Calculates the dot product of two vectors or matrices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27YgbBMBDEg3",
        "outputId": "4ae9d205-4209-40a8-dded-a9daa7844492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TENSOR A: tensor([1, 2, 3])\n",
            "TENSOR B tensor([4, 5, 6])\n",
            "-----------------------------------------------------------------\n",
            "\n",
            "AFTER PERFORMING DOT PRODUCT: tensor(32) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"TENSOR A:\", a)\n",
        "print(\"TENSOR B\", b)\n",
        "print(\"-\" * 65)\n",
        "\n",
        "# Dot product\n",
        "dot_product = torch.matmul(a, b)\n",
        "\n",
        "print(\"\\nAFTER PERFORMING DOT PRODUCT:\", dot_product, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4ok3_d0DEg3"
      },
      "source": [
        "<br>\n",
        "\n",
        "* **Broadcasting**: The automatic expansion of smaller tensors to match the shape of larger tensors during arithmetic operations.\n",
        "    * Broadcasting allows operations between tensors with compatible shapes, even if they don't have the exact same dimensions.\n",
        "    \n",
        "**Understanding Broadcasting**\n",
        "\n",
        "You know that tensors with the same shape will work element by element, but remember how a scalar could update every value in a tensor? When you add a scalar to a tensor, PyTorch automatically expands that single value to match every element. And that's how weight and bias could apply to all of your distances at once. **This automatic expansion is broadcasting in action.**\n",
        "\n",
        "- The NumPy docs for Broadcasting, as it is the same for PyTorch: https://numpy.org/doc/stable/user/basics.broadcasting.html\n",
        "- The PyTorch docs for Broadcasting: https://docs.pytorch.org/docs/stable/notes/broadcasting.html\n",
        "\n",
        "**How Broadcasting Works**\n",
        "\n",
        "Normally, PyTorch requires exact dimension matches for operations. Different shapes would cause an error. But here's the magic: **When one dimension is 1 and the other is larger, PyTorch will automatically expand the smaller dimension by repeating values.**\n",
        "\n",
        "For example:\n",
        "- A tensor with shape `[1, 1]` can broadcast with a tensor of shape `[1, 3]`\n",
        "- The `[1, 1]` tensor becomes `[1, 3]` by repeating the single value\n",
        "- Now they can be added together\n",
        "\n",
        "**More Complex Broadcasting**\n",
        "\n",
        "What happens when you combine a `[1, 3]` tensor with a `[3, 1]` tensor? PyTorch looks at each dimension:\n",
        "- The first dimension: `1` versus `3`. The `1` expands to `3`.\n",
        "- The second dimension: `3` versus `1`. The `1` expands to `3`.\n",
        "- So both become `[3, 3]`.\n",
        "\n",
        "**Why Broadcasting Matters**\n",
        "\n",
        "This pattern appears everywhere in deep learning:\n",
        "- Adjusting multiple features across batches\n",
        "- Combining different dimensions of data\n",
        "- Applying transformations efficiently\n",
        "\n",
        "Instead of manually repeating values or using loops, you can just write the operation. No loops. No manual repetition. PyTorch handles it all through broadcasting. Once you know to look for it, you're going to see broadcasting opportunities everywhere in deep learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "XZdsQ6k7DEg4",
        "outputId": "7c684b4f-153b-421c-e042-31f0e6dc4227"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "No such file or directory: '../../assets/broadcasting_akshay_pachaar.png'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m             \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_repr_mimebundle_\u001b[0;34m(self, include, exclude)\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m             \u001b[0mmimetype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mimetype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1290\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_and_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malways_both\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1291\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m                 \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mmimetype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m             raise FileNotFoundError(\n\u001b[0m\u001b[1;32m   1303\u001b[0m                 \"No such file or directory: '%s'\" % (self.data))\n\u001b[1;32m   1304\u001b[0m         \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: '../../assets/broadcasting_akshay_pachaar.png'"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "No such file or directory: '../../assets/broadcasting_akshay_pachaar.png'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m             \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_png_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FMT_PNG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_and_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_jpeg_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m             raise FileNotFoundError(\n\u001b[0m\u001b[1;32m   1303\u001b[0m                 \"No such file or directory: '%s'\" % (self.data))\n\u001b[1;32m   1304\u001b[0m         \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: '../../assets/broadcasting_akshay_pachaar.png'"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "Image('../../assets/broadcasting_akshay_pachaar.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOl4Sj02DEg4"
      },
      "source": [
        "Checkout these two sources:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1MAEZgdDEg4",
        "outputId": "af5998a4-70e7-409d-d23e-b751bcd74de5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TENSOR A: tensor([1, 2, 3])\n",
            "SHAPE: torch.Size([3])\n",
            "\n",
            "TENSOR B\n",
            "\n",
            " tensor([[1],\n",
            "        [2],\n",
            "        [3]])\n",
            "\n",
            "SHAPE: torch.Size([3, 1])\n",
            "-----------------------------------------------------------------\n",
            "\n",
            "TENSOR C:\n",
            "\n",
            " tensor([[2, 3, 4],\n",
            "        [3, 4, 5],\n",
            "        [4, 5, 6]])\n",
            "\n",
            "SHAPE: torch.Size([3, 3]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([1, 2, 3])\n",
        "b = torch.tensor([[1],\n",
        "                 [2],\n",
        "                 [3]])\n",
        "\n",
        "print(\"TENSOR A:\", a)\n",
        "print(\"SHAPE:\", a.shape)\n",
        "print(\"\\nTENSOR B\\n\\n\", b)\n",
        "print(\"\\nSHAPE:\", b.shape)\n",
        "print(\"-\" * 65)\n",
        "\n",
        "# Apply broadcasting\n",
        "c = a + b\n",
        "\n",
        "\n",
        "print(\"\\nTENSOR C:\\n\\n\", c)\n",
        "print(\"\\nSHAPE:\", c.shape, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08Qa8k2TDEg4"
      },
      "source": [
        "### 4.2 - Logic & Comparisons\n",
        "\n",
        "Logical operations are powerful tools for data preparation and analysis. They allow you to create boolean masks to filter, select, or modify your data based on specific conditions you define.\n",
        "\n",
        "* **Comparison Operators**: Element-wise comparisons (`>`, `==`, `<`) that produce a boolean tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4n6hAFsIp49",
        "outputId": "58b19c7b-d272-4728-b595-ac22f053c43a",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEMPERATURES: tensor([20, 35, 19, 35, 42])\n",
            "--------------------------------------------------\n",
            "\n",
            "HOT (> 30 DEGREES): tensor([False,  True, False,  True,  True])\n",
            "COOL (<= 20 DEGREES): tensor([ True, False,  True, False, False])\n",
            "EXACTLY 35 DEGREES: tensor([False,  True, False,  True, False]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "temperatures = torch.tensor([20, 35, 19, 35, 42])\n",
        "print(\"TEMPERATURES:\", temperatures)\n",
        "print(\"-\" * 50)\n",
        "\n",
        "### Comparison Operators (>, <, ==)\n",
        "\n",
        "# Use '>' (greater than) to find temperatures above 30\n",
        "is_hot = temperatures > 30\n",
        "\n",
        "# Use '<=' (less than or equal to) to find temperatures 20 or below\n",
        "is_cool = temperatures <= 20\n",
        "\n",
        "# Use '==' (equal to) to find temperatures exactly equal to 35\n",
        "is_35_degrees = temperatures == 35\n",
        "\n",
        "print(\"\\nHOT (> 30 DEGREES):\", is_hot)\n",
        "print(\"COOL (<= 20 DEGREES):\", is_cool)\n",
        "print(\"EXACTLY 35 DEGREES:\", is_35_degrees, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anBSGyD-DEg5"
      },
      "source": [
        "<br>\n",
        "\n",
        "* **Logical Operators**: Element-wise logical operations (`&` for **AND**, `|` for **OR**) on boolean tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmEU32D4LDih",
        "outputId": "22516974-71ee-4df8-e9d4-f3fee52fde31",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IS MORNING: tensor([ True, False, False,  True])\n",
            "IS RAINING: tensor([False, False,  True,  True])\n",
            "--------------------------------------------------\n",
            "\n",
            "MORNING & (AND) RAINING: tensor([False, False, False,  True])\n",
            "MORNING | (OR) RAINING: tensor([ True, False,  True,  True])\n"
          ]
        }
      ],
      "source": [
        "is_morning = torch.tensor([True, False, False, True])\n",
        "is_raining = torch.tensor([False, False, True, True])\n",
        "print(\"IS MORNING:\", is_morning)\n",
        "print(\"IS RAINING:\", is_raining)\n",
        "print(\"-\" * 50)\n",
        "\n",
        "### Logical Operators (&, |)\n",
        "\n",
        "# Use '&' (AND) to find when it's both morning and raining\n",
        "morning_and_raining = (is_morning & is_raining)\n",
        "\n",
        "# Use '|' (OR) to find when it's either morning or raining\n",
        "morning_or_raining = is_morning | is_raining\n",
        "\n",
        "print(\"\\nMORNING & (AND) RAINING:\", morning_and_raining)\n",
        "print(\"MORNING | (OR) RAINING:\", morning_or_raining)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b19tKeK-DEg6"
      },
      "source": [
        "### 4.3 - Statistics\n",
        "\n",
        "Calculating statistics like the mean or standard deviation can be useful for understanding your dataset or for implementing certain types of normalization during the data preparation phase.\n",
        "\n",
        "* `torch.mean()`: Calculates the mean of all elements in a tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx8BLrE-DEg6",
        "outputId": "fb5bf265-5c11-4a3a-e7a7-5c1d7e5fc62f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA: tensor([10., 20., 30., 40., 50.])\n",
            "---------------------------------------------\n",
            "\n",
            "CALCULATED MEAN: tensor(30.) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "data = torch.tensor([10.0, 20.0, 30.0, 40.0, 50.0])\n",
        "print(\"DATA:\", data)\n",
        "print(\"-\" * 45)\n",
        "\n",
        "# Calculate the mean\n",
        "data_mean = data.mean()\n",
        "\n",
        "print(\"\\nCALCULATED MEAN:\", data_mean, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plUVGQK0DEg7"
      },
      "source": [
        "<br>\n",
        "\n",
        "* `torch.std()`: Calculates the standard deviation of all elements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giolRmF7DEg7",
        "outputId": "4ec27328-db5d-40c4-9544-1710975f8944"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA: tensor([10., 20., 30., 40., 50.])\n",
            "---------------------------------------------\n",
            "\n",
            "CALCULATED STD: tensor(15.8114) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"DATA:\", data)\n",
        "print(\"-\" * 45)\n",
        "\n",
        "# Calculate the standard deviation\n",
        "data_std = data.std()\n",
        "\n",
        "print(\"\\nCALCULATED STD:\", data_std, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l95uTo51DEg8"
      },
      "source": [
        "### 4.4 - Data Types\n",
        "\n",
        "Just as important as a tensor's shape is its data type. Neural networks typically perform their calculations using 32-bit floating point numbers (float32). Providing data of the wrong type, such as an integer, can lead to runtime errors or unexpected behavior during training. It is a good practice to ensure your tensors have the correct data type for your model.\n",
        "\n",
        "**Understanding Data Types in PyTorch**\n",
        "\n",
        "When you create a tensor, PyTorch can use defaults:\n",
        "- If you enter integers, you'll get `int64`\n",
        "- If you include a decimal point, then you'll get `float32`\n",
        "- If you want to be explicit, you can use the `dtype` argument. It guarantees `float32` even if you forget the decimal point\n",
        "- Alternatively, you can use `.float()` to convert any tensor to `float32`\n",
        "\n",
        "**Type Promotion**\n",
        "\n",
        "What happens if you mix types? It used to be the case that PyTorch would throw an error when you try to mix dtypes. That's no longer true. Now PyTorch will automatically handle mixed types through **type promotion**. For example, if you add an int tensor and a float tensor, PyTorch will automatically convert the int to float and then return a float result, just like regular Python.\n",
        "\n",
        "**Choosing the Right Type**\n",
        "\n",
        "There are other types too, like `float64` for extra precision or `int8` for memory savings. But for neural networks, **`float32` is the sweet spot**. It's fast, accurate, and standard on modern hardware.\n",
        "\n",
        "* **Type Casting (`.int()`, `.float()`, etc.)**: Converts a tensor from one data type to another (e.g., from float to integer)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR36YZhBDEg8",
        "outputId": "3ab3680a-e8ec-4f19-ce00-23be2e54a0fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA: tensor([10., 20., 30., 40., 50.])\n",
            "DATA TYPE: torch.float32\n",
            "---------------------------------------------\n",
            "\n",
            "CASTED DATA: tensor([10, 20, 30, 40, 50], dtype=torch.int32)\n",
            "CASTED DATA TYPE torch.int32\n"
          ]
        }
      ],
      "source": [
        "print(\"DATA:\", data)\n",
        "print(\"DATA TYPE:\", data.dtype)\n",
        "print(\"-\" * 45)\n",
        "\n",
        "# Cast the tensor to a int type\n",
        "int_tensor = data.int()\n",
        "\n",
        "print(\"\\nCASTED DATA:\", int_tensor)\n",
        "print(\"CASTED DATA TYPE\", int_tensor.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXCjxVFIDEg8"
      },
      "source": [
        "## 5 - Optional Exercises\n",
        "\n",
        "You've now covered the essential tools for working with tensors in PyTorch. Theory provides the map, but hands-on practice is what builds true confidence and skill. The following optional exercises are your opportunity to apply what you have learned to practical scenarios, from analyzing sales data to engineering new features for a machine learning model. This is where the concepts truly come to life, so dive in and put your new knowledge to the test!\n",
        "\n",
        "### Exercise 1: Analyzing Monthly Sales Data\n",
        "\n",
        "You're a data analyst at an e-commerce company. You've been given a tensor representing the monthly sales of three different products over a period of four months. Your task is to extract meaningful insights from this data.\n",
        "\n",
        "The tensor `sales_data` is structured as follows:\n",
        "\n",
        "* **Rows** represent the **products** (Product A, Product B, Product C).\n",
        "\n",
        "* **Columns** represent the **months** (Jan, Feb, Mar, Apr).\n",
        "\n",
        "**Your goals are**:\n",
        "\n",
        "1. Calculate the total sales for **Product B** (the second row).\n",
        "2. Identify which months had sales **greater than 130** for **Product C** (the third row) using boolean masking.\n",
        "3. Extract the sales data for all products for the months of **Feb and Mar** (the middle two columns).\n",
        "\n",
        "<br>\n",
        "\n",
        "<details>\n",
        "<summary><span style=\"color:green;\"><strong>Solution (Click here to expand)</strong></span></summary>\n",
        "\n",
        "```python\n",
        "### START CODE HERE ###\n",
        "\n",
        "# 1. Calculate total sales for Product B.\n",
        "total_sales_product_b = sales_data[1].sum()\n",
        "\n",
        "# 2. Find months where sales for Product C were > 130.\n",
        "high_sales_mask_product_c = sales_data[2] > 130\n",
        "\n",
        "# 3. Get sales for Feb and Mar for all products.\n",
        "sales_feb_mar = sales_data[:, 1:3]\n",
        "\n",
        "### END CODE HERE ###\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "blELUaFGDEg9",
        "outputId": "78749c08-2ae0-4f5b-8b54-2e79e6490058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL SALES DATA:\n",
            "\n",
            " tensor([[100., 120., 130., 110.],\n",
            "        [ 90.,  95., 105., 125.],\n",
            "        [140., 115., 120., 150.]])\n",
            "---------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name '__BLANK__' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2708637459.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 1. Calculate total sales for Product B.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtotal_sales_product_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__BLANK__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# 2. Find months where sales for Product C were > 130.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name '__BLANK__' is not defined"
          ]
        }
      ],
      "source": [
        "# Sales data for 3 products over 4 months\n",
        "sales_data = torch.tensor([[100, 120, 130, 110],   # Product A\n",
        "                           [ 90,  95, 105, 125],   # Product B\n",
        "                           [140, 115, 120, 150]    # Product C\n",
        "                          ], dtype=torch.float32)\n",
        "\n",
        "print(\"ORIGINAL SALES DATA:\\n\\n\", sales_data)\n",
        "print(\"-\" * 45)\n",
        "\n",
        "### START CODE HERE ###\n",
        "\n",
        "# 1. Calculate total sales for Product B.\n",
        "total_sales_product_b = __BLANK__\n",
        "\n",
        "# 2. Find months where sales for Product C were > 130.\n",
        "high_sales_mask_product_c = __BLANK__\n",
        "\n",
        "# 3. Get sales for Feb and Mar for all products.\n",
        "sales_feb_mar = __BLANK__\n",
        "\n",
        "### END CODE HERE ###\n",
        "\n",
        "print(\"\\nTotal Sales for Product B:                   \", total_sales_product_b)\n",
        "print(\"\\nMonths with >130 Sales for Product C (Mask): \", high_sales_mask_product_c)\n",
        "print(\"\\nSales for Feb & Mar:\\n\\n\", sales_feb_mar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaCwkDGODEg9"
      },
      "source": [
        "#### Expected Output:\n",
        "\n",
        "```\n",
        "Total Sales for Product B:\t\t\t tensor(415.)\n",
        "\n",
        "Months with >130 Sales for Product C (Mask):\t tensor([ True, False, False,  True])\n",
        "\n",
        "Sales for Feb & Mar:\n",
        "\n",
        " tensor([[120., 130.],\n",
        "        [ 95., 105.],\n",
        "        [115., 120.]])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KEeQ-6kDEg9"
      },
      "source": [
        "### Exercise 2: Image Batch Transformation\n",
        "\n",
        "You're working on a computer vision model and have a batch of 4 grayscale images, each of size 3x3 pixels. The data is currently in a tensor with the shape `[4, 3, 3]`, which represents `[batch_size, height, width]`.\n",
        "\n",
        "For processing with certain deep learning frameworks, you need to transform this data into the `[batch_size, channels, height, width]` format. Since the images are grayscale, **you'll need to**:\n",
        "\n",
        "1. Add a new dimension of size 1 at index 1 to represent the color channel.\n",
        "2. After adding the channel, you realize the model expects the shape `[batch_size, height, width, channels]`. Transpose the tensor to swap the channel dimension with the last dimension.\n",
        "\n",
        "<br>\n",
        "\n",
        "<details>\n",
        "<summary><span style=\"color:green;\"><strong>Solution (Click here to expand)</strong></span></summary>\n",
        "\n",
        "```python\n",
        "### START CODE HERE ###\n",
        "\n",
        "# 1. Add a channel dimension at index 1.\n",
        "image_batch_with_channel = image_batch.unsqueeze(1)\n",
        "\n",
        "# 2. Transpose the tensor to move the channel dimension to the end.\n",
        "# Swap dimension 1 (channels) with dimension 3 (the last one).\n",
        "image_batch_transposed = image_batch_with_channel.transpose(1, 3)\n",
        "\n",
        "### END CODE HERE ###\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyPAkwaiDEg-",
        "outputId": "4b9e8bef-0a8e-4871-98e2-e98617ba43ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL BATCH SHAPE: torch.Size([4, 3, 3])\n",
            "---------------------------------------------\n",
            "\n",
            "SHAPE AFTER UNSQUEEZE: torch.Size([4, 1, 3, 3])\n",
            "SHAPE AFTER TRANSPOSE: torch.Size([4, 3, 3, 1])\n"
          ]
        }
      ],
      "source": [
        "# A batch of 4 grayscale images, each 3x3\n",
        "image_batch = torch.rand(4, 3, 3)\n",
        "\n",
        "print(\"ORIGINAL BATCH SHAPE:\", image_batch.shape)\n",
        "print(\"-\" * 45)\n",
        "\n",
        "### START CODE HERE ###\n",
        "\n",
        "# 1. Add a channel dimension at index 1.\n",
        "image_batch_with_channel = image_batch.unsqueeze(1)\n",
        "# 2. Transpose the tensor to move the channel dimension to the end.\n",
        "# Swap dimension 1 (channels) with dimension 3 (the last one).\n",
        "image_batch_transposed = image_batch_with_channel.transpose(1, 3)\n",
        "\n",
        "### END CODE HERE ###\n",
        "\n",
        "\n",
        "print(\"\\nSHAPE AFTER UNSQUEEZE:\", image_batch_with_channel.shape)\n",
        "print(\"SHAPE AFTER TRANSPOSE:\", image_batch_transposed.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0kum6qIDEg-"
      },
      "source": [
        "#### Expected Output:\n",
        "\n",
        "```\n",
        "SHAPE AFTER UNSQUEEZE: torch.Size([4, 1, 3, 3])\n",
        "SHAPE AFTER TRANSPOSE: torch.Size([4, 3, 3, 1])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDkNhxMaDEg-"
      },
      "source": [
        "### Exercise 3: Combining and Weighting Sensor Data\n",
        "\n",
        "You're building an environment monitoring system that uses two sensors: one for temperature and one for humidity. You receive data from these sensors as two separate 1D tensors.\n",
        "\n",
        "**Your task is to**:\n",
        "\n",
        "1. **Concatenate** the two tensors into a single `2x5` tensor, where the first row is temperature data and the second is humidity data.\n",
        "2. Create a `weights` tensor `torch.tensor([0.6, 0.4])`.\n",
        "3. Use **broadcasting and element-wise multiplication** to apply these weights to the combined sensor data. The temperature data should be multiplied by 0.6 and the humidity data by 0.4.\n",
        "4. Finally, calculate the **weighted average** for each time step by **summing** the weighted values along `dim=0` and **dividing** by the sum of the weights.\n",
        "\n",
        "<br>\n",
        "\n",
        "<details>\n",
        "<summary><span style=\"color:green;\"><strong>Solution (Click here to expand)</strong></span></summary>\n",
        "\n",
        "```python\n",
        "### START CODE HERE ###\n",
        "\n",
        "# 1. Concatenate the two tensors.\n",
        "# Note: You need to unsqueeze them first to stack them vertically.\n",
        "combined_data = torch.cat((temperature.unsqueeze(0), humidity.unsqueeze(0)), dim=0)\n",
        "\n",
        "# 2. Create the weights tensor.\n",
        "weights = torch.tensor([0.6, 0.4])\n",
        "\n",
        "# 3. Apply weights using broadcasting.\n",
        "# You need to reshape weights to [2, 1] to broadcast across columns.\n",
        "weighted_data = combined_data * weights.unsqueeze(1)\n",
        "\n",
        "# 4. Calculate the weighted average for each time step.\n",
        "#    (A true average = weighted sum / sum of weights)\n",
        "weighted_sum = torch.sum(weighted_data, dim=0)\n",
        "weighted_average = weighted_sum / torch.sum(weights)\n",
        "\n",
        "### END CODE HERE ###\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuryATkaDEg-",
        "outputId": "ad9a961f-462b-4e1e-cb3e-41bf6e4a9e8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEMPERATURE DATA:  tensor([22.5000, 23.1000, 21.9000, 22.8000, 23.5000])\n",
            "HUMIDITY DATA:     tensor([55.2000, 56.4000, 54.8000, 57.1000, 56.8000])\n",
            "---------------------------------------------\n",
            "\n",
            "COMBINED DATA (2x5):\n",
            "\n",
            " tensor([[22.5000, 23.1000, 21.9000, 22.8000, 23.5000],\n",
            "        [55.2000, 56.4000, 54.8000, 57.1000, 56.8000]])\n",
            "\n",
            "WEIGHTED DATA:\n",
            "\n",
            " tensor([[11.2500, 11.5500, 10.9500, 11.4000, 11.7500],\n",
            "        [11.0400, 11.2800, 10.9600, 11.4200, 11.3600]])\n",
            "\n",
            "WEIGHTED AVERAGE: tensor([31.8429, 32.6143, 31.3000, 32.6000, 33.0143])\n"
          ]
        }
      ],
      "source": [
        "# Sensor readings (5 time steps)\n",
        "temperature = torch.tensor([22.5, 23.1, 21.9, 22.8, 23.5])\n",
        "humidity = torch.tensor([55.2, 56.4, 54.8, 57.1, 56.8])\n",
        "\n",
        "print(\"TEMPERATURE DATA: \", temperature)\n",
        "print(\"HUMIDITY DATA:    \", humidity)\n",
        "print(\"-\" * 45)\n",
        "\n",
        "### START CODE HERE ###\n",
        "\n",
        "# 1. Concatenate the two tensors.\n",
        "# Note: You need to unsqueeze them first to stack them vertically.\n",
        "combined_data = torch.cat(\n",
        "    (temperature.unsqueeze(0), humidity.unsqueeze(0)),\n",
        "    dim=0\n",
        ")\n",
        "\n",
        "\n",
        "# 2. Create the weights tensor.\n",
        "weights = torch.tensor([0.5, 0.2])\n",
        "\n",
        "# 3. Apply weights using broadcasting.\n",
        "# You need to reshape weights to [2, 1] to broadcast across columns.\n",
        "weighted_data = combined_data * weights.unsqueeze(1)\n",
        "\n",
        "# 4. Calculate the weighted average for each time step.\n",
        "#    (A true average = weighted sum / sum of weights)\n",
        "weighted_sum = weighted_data.sum(dim=0)\n",
        "weighted_average = weighted_sum / weights.sum()\n",
        "\n",
        "### END CODE HERE ###\n",
        "\n",
        "print(\"\\nCOMBINED DATA (2x5):\\n\\n\", combined_data)\n",
        "print(\"\\nWEIGHTED DATA:\\n\\n\", weighted_data)\n",
        "print(\"\\nWEIGHTED AVERAGE:\", weighted_average)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-cq_5IlDEg_"
      },
      "source": [
        "#### Expected Output:\n",
        "\n",
        "```\n",
        "COMBINED DATA (2x5):\n",
        "\n",
        " tensor([[22.5000, 23.1000, 21.9000, 22.8000, 23.5000],\n",
        "        [55.2000, 56.4000, 54.8000, 57.1000, 56.8000]])\n",
        "\n",
        "WEIGHTED DATA:\n",
        "\n",
        " tensor([[13.5000, 13.8600, 13.1400, 13.6800, 14.1000],\n",
        "        [22.0800, 22.5600, 21.9200, 22.8400, 22.7200]])\n",
        "\n",
        "WEIGHTED AVERAGE: tensor([35.5800, 36.4200, 35.0600, 36.5200, 36.8200])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAnO3kunDEg_"
      },
      "source": [
        "### Exercise 4: Feature Engineering for Taxi Fares\n",
        "\n",
        "You are working with a dataset of taxi trips. You have a tensor, `trip_data`, where each row is a trip and the columns represent **[distance (km), hour_of_day (24h)]**.\n",
        "\n",
        "**Your goal** is to engineer a new binary feature called `is_rush_hour_long_trip`. This feature should be `True` (or `1`) only if a trip meets **both** of the following criteria:\n",
        "\n",
        "* It's a **long trip** (distance > 10 km).\n",
        "* It occurs during a **rush hour** (8-10 AM or 5-7 PM, i.e., `[8, 10)` or `[17, 19)`).\n",
        "\n",
        "To achieve this, you will need to:\n",
        "\n",
        "1. **Slice** the `trip_data` tensor to isolate the `distance` and `hour` columns.\n",
        "2. Use **logical and comparison operators** to create boolean masks for each condition (long trip, morning rush, evening rush).\n",
        "3. Combine these masks to create the final `is_rush_hour_long_trip` feature.\n",
        "4. **Reshape** this new 1D feature tensor into a 2D column vector and convert its data type to float so it can be combined with the original data.\n",
        "\n",
        "<br>\n",
        "\n",
        "<details>\n",
        "<summary><span style=\"color:green;\"><strong>Solution (Click here to expand)</strong></span></summary>\n",
        "\n",
        "```python\n",
        "### START CODE HERE ###\n",
        "\n",
        "# 1. Slice the main tensor to get 1D tensors for each feature.\n",
        "distances = trip_data[:, 0]\n",
        "hours = trip_data[:, 1]\n",
        "\n",
        "# 2. Create boolean masks for each condition.\n",
        "is_long_trip = distances > 10.0\n",
        "is_morning_rush = (hours >= 8.0) & (hours < 10.0)\n",
        "is_evening_rush = (hours >= 17.0) & (hours < 19.0)\n",
        "\n",
        "# 3. Combine masks to identify rush hour long trips.\n",
        "# A trip is a rush hour long trip if it's (a morning OR evening rush) AND a long trip.\n",
        "is_rush_hour_long_trip_mask = (is_morning_rush | is_evening_rush) & is_long_trip\n",
        "\n",
        "# 4. Reshape the new feature into a column vector and cast to float.\n",
        "new_feature_col = is_rush_hour_long_trip_mask.float().unsqueeze(1)\n",
        "\n",
        "### END CODE HERE ###\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "tags": [],
        "id": "GajcM5PyDEg_"
      },
      "outputs": [],
      "source": [
        "# Data for 8 taxi trips: [distance, hour_of_day]\n",
        "trip_data = torch.tensor([\n",
        "    [5.3, 7],   # Not rush hour, not long\n",
        "    [12.1, 9],  # Morning rush, long trip -> RUSH HOUR LONG\n",
        "    [15.5, 13], # Not rush hour, long trip\n",
        "    [6.7, 18],  # Evening rush, not long\n",
        "    [2.4, 20],  # Not rush hour, not long\n",
        "    [11.8, 17], # Evening rush, long trip -> RUSH HOUR LONG\n",
        "    [9.0, 9],   # Morning rush, not long\n",
        "    [14.2, 8]   # Morning rush, long trip -> RUSH HOUR LONG\n",
        "], dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXrgaLroDEg_",
        "outputId": "a7f7c969-670f-4aab-be06-df8c4cd32d86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([False,  True, False, False, False,  True, False,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "distance = trip_data[:,0]\n",
        "hour = trip_data[:, 1]\n",
        "is_long_trip = distance > 10\n",
        "is_rush_hour = ((8 <= hour) & (hour < 10)) | ((17 <= hour) & (hour < 19))\n",
        "is_rush_hour_long_trip = is_long_trip & is_rush_hour\n",
        "is_rush_hour_long_trip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyORMLXXDEg_",
        "outputId": "792420ca-0b77-4b41-8491-6beb03b953aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "trip_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFOv_I0oDEhA",
        "outputId": "94293e9b-7e79-4e33-dec3-00e8c4ef1993"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "reshaped = is_rush_hour_long_trip.unsqueeze(dim=0).transpose(0, 1)\n",
        "reshaped.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH6u__QtDEhA",
        "outputId": "a20873ef-63b3-4c59-9ea4-20c7d81e646f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.3000,  7.0000,  0.0000],\n",
              "        [12.1000,  9.0000,  1.0000],\n",
              "        [15.5000, 13.0000,  0.0000],\n",
              "        [ 6.7000, 18.0000,  0.0000],\n",
              "        [ 2.4000, 20.0000,  0.0000],\n",
              "        [11.8000, 17.0000,  1.0000],\n",
              "        [ 9.0000,  9.0000,  0.0000],\n",
              "        [14.2000,  8.0000,  1.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "torch.concat((trip_data, reshaped), dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-TF1sy-DEhA",
        "outputId": "d64d50ca-49dc-4332-9fed-16d19b9ac48e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL TRIP DATA (Distance, Hour):\n",
            "\n",
            " tensor([[ 5.3000,  7.0000],\n",
            "        [12.1000,  9.0000],\n",
            "        [15.5000, 13.0000],\n",
            "        [ 6.7000, 18.0000],\n",
            "        [ 2.4000, 20.0000],\n",
            "        [11.8000, 17.0000],\n",
            "        [ 9.0000,  9.0000],\n",
            "        [14.2000,  8.0000]])\n",
            "-------------------------------------------------------\n",
            "\n",
            "'IS RUSH HOUR LONG TRIP' MASK:  tensor([False,  True, False, False, False, False, False,  True])\n",
            "\n",
            "NEW FEATURE COLUMN (Reshaped):\n",
            "\n",
            " tensor([[0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.]])\n",
            "\n",
            "ENHANCED DATA (with new feature at the end):\n",
            "\n",
            " tensor([[ 5.3000,  7.0000,  0.0000],\n",
            "        [12.1000,  9.0000,  1.0000],\n",
            "        [15.5000, 13.0000,  0.0000],\n",
            "        [ 6.7000, 18.0000,  0.0000],\n",
            "        [ 2.4000, 20.0000,  0.0000],\n",
            "        [11.8000, 17.0000,  0.0000],\n",
            "        [ 9.0000,  9.0000,  0.0000],\n",
            "        [14.2000,  8.0000,  1.0000]])\n"
          ]
        }
      ],
      "source": [
        "# Data for 8 taxi trips: [distance, hour_of_day]\n",
        "trip_data = torch.tensor([\n",
        "    [5.3, 7],   # Not rush hour, not long\n",
        "    [12.1, 9],  # Morning rush, long trip -> RUSH HOUR LONG\n",
        "    [15.5, 13], # Not rush hour, long trip\n",
        "    [6.7, 18],  # Evening rush, not long\n",
        "    [2.4, 20],  # Not rush hour, not long\n",
        "    [11.8, 17], # Evening rush, long trip -> RUSH HOUR LONG\n",
        "    [9.0, 9],   # Morning rush, not long\n",
        "    [14.2, 8]   # Morning rush, long trip -> RUSH HOUR LONG\n",
        "], dtype=torch.float32)\n",
        "\n",
        "\n",
        "print(\"ORIGINAL TRIP DATA (Distance, Hour):\\n\\n\", trip_data)\n",
        "print(\"-\" * 55)\n",
        "\n",
        "\n",
        "### START CODE HERE ###\n",
        "\n",
        "# 1. Slice the main tensor to get 1D tensors for each feature.\n",
        "distances = trip_data[:, 0]\n",
        "hours = trip_data[:, 1]\n",
        "\n",
        "\n",
        "# 2. Create boolean masks for each condition.\n",
        "is_long_trip = distances > 12\n",
        "is_morning_rush = (hours >= 7) & (hours <= 9)\n",
        "is_evening_rush = (hours >= 17) & (hours <= 18)\n",
        "\n",
        "\n",
        "# 3. Combine masks to identify rush hour long trips.\n",
        "# A trip is a rush hour long trip if it's (a morning OR evening rush) AND a long trip.\n",
        "is_rush_hour_long_trip_mask = (is_morning_rush | is_evening_rush) & is_long_trip\n",
        "\n",
        "# 4. Reshape the new feature into a column vector and cast to float.\n",
        "new_feature_col = is_rush_hour_long_trip_mask.unsqueeze(1).float()\n",
        "\n",
        "\n",
        "### END CODE HERE ###\n",
        "\n",
        "print(\"\\n'IS RUSH HOUR LONG TRIP' MASK: \", is_rush_hour_long_trip_mask)\n",
        "print(\"\\nNEW FEATURE COLUMN (Reshaped):\\n\\n\", new_feature_col)\n",
        "\n",
        "# You can now concatenate this new feature to the original data\n",
        "enhanced_trip_data = torch.cat((trip_data, new_feature_col), dim=1)\n",
        "print(\"\\nENHANCED DATA (with new feature at the end):\\n\\n\", enhanced_trip_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqICrYzADEhA"
      },
      "source": [
        "#### Expected Output:\n",
        "\n",
        "```\n",
        "'IS RUSH HOUR LONG TRIP' MASK:  tensor([False,  True, False, False, False,  True, False,  True])\n",
        "\n",
        "NEW FEATURE COLUMN (Reshaped):\n",
        "\n",
        " tensor([[0.],\n",
        "        [1.],\n",
        "        [0.],\n",
        "        [0.],\n",
        "        [0.],\n",
        "        [1.],\n",
        "        [0.],\n",
        "        [1.]])\n",
        "\n",
        "ENHANCED DATA (with new feature at the end):\n",
        "\n",
        " tensor([[ 5.3000,  7.0000,  0.0000],\n",
        "        [12.1000,  9.0000,  1.0000],\n",
        "        [15.5000, 13.0000,  0.0000],\n",
        "        [ 6.7000, 18.0000,  0.0000],\n",
        "        [ 2.4000, 20.0000,  0.0000],\n",
        "        [11.8000, 17.0000,  1.0000],\n",
        "        [ 9.0000,  9.0000,  0.0000],\n",
        "        [14.2000,  8.0000,  1.0000]])\n",
        "```        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgaMfmcUDEhB"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "Congratulations on completing this lab! You have now worked through the fundamental building blocks of PyTorch. You started with an empty slate and learned to create, reshape, combine, and query tensors in various ways.\n",
        "\n",
        "The skills you have developed here are essential for every machine learning practitioner. The element-wise arithmetic and broadcasting you practiced are precisely how a neural network efficiently applies weights and biases to entire batches of data at once. The reshaping techniques like `unsqueeze` and `squeeze` are what allow you to prepare a single data point for a model that expects a batch, and then clean up the output afterward. These are not just abstract exercises; they are the day-to-day operations required to build and debug effective deep learning models.\n",
        "\n",
        "With this solid understanding of tensors, you are now fully prepared to move on to the next stage: building and training neural networks to solve even more complex problems. Every model you build from now on will stand on this foundation."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}